{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from laughing.rrtf_train import *\n",
        "from laughing import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated GPU Memory: 0.00 GB\n",
            "Maximum Allocated GPU Memory: 0.00 GB\n",
            "Available GPU Memory: 15.78 GB\n"
          ]
        }
      ],
      "source": [
        "utils.free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model_args = ModelArguments(model_name_or_path='facebook/opt-125m')\n",
        "model_args = ModelArguments(model_name_or_path='microsoft/phi-1_5')\n",
        "data_args = DataArguments(data_path='../data/tiny_responses.json')\n",
        "#data_args = DataArguments(data_path='../data/alpaca_responses_hh.json')\n",
        "\n",
        "training_args = TrainingArguments(model_max_length=1024, report_to=\"none\", cache_dir='../cache',\n",
        "                                  output_dir='../tmp_outputs', gradient_checkpointing=True,\n",
        "                                  # batch_size must be 1 for loss calculation to work\n",
        "                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "                                  # My device doesn't work with accumation due to limited memory\n",
        "                                  #gradient_accumulation_steps=8\n",
        "                                  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading model...\n",
            "creating a peft model with lora (rank=1)...\n",
            "trainable params: 196,608 || all params: 1,418,467,328 || trainable%: 0.013860594186347027\n",
            "loading tokenizer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Loading data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 01:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer, result = train(model_args, data_args, training_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'train_runtime': 70.3702,\n",
              "  'train_samples_per_second': 4.263,\n",
              "  'train_steps_per_second': 4.263,\n",
              "  'total_flos': 2837680752181248.0,\n",
              "  'train_loss': 1.9220037841796875,\n",
              "  'epoch': 3.0,\n",
              "  'step': 300}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.state.log_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.print_summary(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i am eating \n",
            "\n",
            "Answer: I am eating a sandwich.\n",
            "\n",
            "Exercise 2: Identify the verb in the following sentence: The cat is sleeping on the couch.\n",
            "\n",
            "Answer: Sleeping\n",
            "\n",
            "Exercise 3: Identify the noun in the following sentence: The book on the table is mine.\n",
            "\n",
            "Answer: Book, table, mine\n",
            "\n",
            "Exercise 4: Identify the adjective in the following sentence: The red car is parked outside.\n",
            "\n",
            "Answer: Red\n",
            "\n",
            "Exercise 5: Identify the adverb in the following sentence: She sings beautifully.\n",
            "\n",
            "Answer: Beautifully\n",
            "\n",
            "In conclusion, understanding grammar is essential for effective communication. Verbs and nouns are the building blocks of language, and knowing how to use them correctly can help you express yourself clearly and accurately. By practicing and applying these concepts in real-world situations, you can become a better communicator and achieve your goals, whether you want to be a doctor, a teacher, or a chef.\n",
            "\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    inputs = trainer.tokenizer('i am eating ', return_tensors=\"pt\", return_attention_mask=False,\n",
        "                       padding=True, truncation=True).to('cuda')\n",
        "    outputs = trainer.model.generate(**inputs, max_new_tokens=300,\n",
        "                             eos_token_id=trainer.tokenizer.eos_token_id)\n",
        "    texts = trainer.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    print(texts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
