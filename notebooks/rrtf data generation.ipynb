{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-28 06:03:48.969310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 06:03:49.991280: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-09-28 06:03:49.997680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-09-28 06:03:49.997696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from laughing import phi15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "model, _, tokenizer = phi15.load_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# this file contains original instruction and test cases generated by fine-tuned phi1_5 and gpt4 teacher\n",
    "test_cases_file = '../data/phi15_generated_test_cases_train.json'\n",
    "\n",
    "with open(test_cases_file, encoding='utf-8') as fin:\n",
    "  data = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3297"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Fix the following function to make it comply with PEP8 standards.',\n",
       " 'input': 'def f(x):\\nk= x+4\\nreturn k',\n",
       " 'output': 'def f(x):\\n    k = x + 4\\n    return k',\n",
       " 'test_cases': 'def test_positive_number():\\n    assert f(5) == 9\\n\\ndef test_negative_number():\\n    assert f(-3) == 1\\n\\ndef test_zero():\\n    assert f(0) == 4\\n\\ndef test_float_number():\\n    assert f(2.5) == 6.5\\n',\n",
       " 'phi_finetuned_test_cases': \"Generate unit tests for the below problem and its solution in Python.\\n    Write each unit test as a seperate Python function with meaningful name that starts with 'test_'.\\n\\n    Problem:\\n    Fix the following function to make it comply with PEP8 standards.\\n\\n    Solution:\\n    def f(x):\\n    k = x + 4\\n    return k\\n\\n    Test cases:\\n    def test_generate_sum_of_squares():\\n        assert f(5) == 25\\n        assert f(6) == 41\\n        assert f(7) == 100\\n        assert f(8) == 121\\n        assert f(9) == 121\\n        assert f(10) == 121\\n        assert f(11) == 121\\n        assert f(12) == 121\\n        assert f(13) == 121\\n        assert f(14) == 121\\n        assert f(15) == 121\\n        assert f(16) == 121\\n        assert f(17) == 121\\n        assert f(18) == 121\\n        assert f(19) == 121\\n        assert f(20) == 121\\n        assert f(21) == 121\\n        assert f(22) == 121\\n        assert f(23) == 121\\n        assert f(24) == 121\\n        assert f(25) == 121\\n        assert f(26) == 121\\n        assert f(27) == 121\\n        assert f(28) == 121\\n        assert f(29) == 121\\n        assert f(30) == 121\\n        assert f(31) == 121\\n        assert f(32) == 121\\n        assert f(33) == 121\\n        assert f(34) == 121\\n        assert f(35) == 121\\n        assert\",\n",
       " 'split': 'train'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate outputs for the entire dataset\n",
    "batch_size = 20\n",
    "responses = []\n",
    "\n",
    "def generate(model, tokenizer, data, responses=[]):\n",
    "    for i in range(len(responses), len(data), batch_size):\n",
    "        print(i, end=' ')\n",
    "        prompts = phi15.make_prompts_for_code_gen(data[i:i+batch_size])\n",
    "        responses.extend(phi15.gen_n_prompts(model, tokenizer, prompts))\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "responses = generate(model, tokenizer, data[0:5], responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, response in zip(data, responses):\n",
    "    task['phi_base_output'] = phi15.extract_program(response)\n",
    "    #task['gpt4_test_cases'] = task['test_cases']\n",
    "    #task.pop('test_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the program output from base phi15 model\n",
    "with open('../data/code_alpaca_v2.json', encoding='utf-8', mode='w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phi15 fine-tuned model and generate test cases using the generated program\n",
    "# run batch eval for test cases\n",
    "# prepare training for RRTH\n",
    "# train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig, AutoPeftModelForCausalLM\n",
    "\n",
    "#model, peft_model, tokenizer = phi15.load_model_and_tokenizer(lora_rank=2)\n",
    "#peft_config = PeftConfig.from_pretrained('../../phi15_finetuned_for_tests_generation/')\n",
    "#peft_model = PeftModel.from_pretrained(model, '../../phi15_finetuned_for_tests_generation/')\n",
    "peft_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    '../phi15_finetuned_outputs_20230928/checkpoint-824/', trust_remote_code=True)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=torch.float32)\n",
    "#peft_model = PeftModel.from_pretrained(model, \"Vasanth/phi-1_5-finetuned-gsm8k\", from_transformers=True)\n",
    "#model = peft_model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.layers.1.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0034,  0.0221,  0.0197,  ..., -0.0241, -0.0305, -0.0147],\n",
      "        [ 0.0086,  0.0162,  0.0369,  ..., -0.0409, -0.0021, -0.0226]])\n",
      "base_model.model.layers.1.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0027, -0.0005],\n",
      "        [-0.0052, -0.0022],\n",
      "        [-0.0059, -0.0006],\n",
      "        ...,\n",
      "        [-0.0026, -0.0043],\n",
      "        [-0.0062, -0.0070],\n",
      "        [-0.0049, -0.0048]])\n",
      "base_model.model.layers.2.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0139,  0.0159,  0.0140,  ...,  0.0372,  0.0312, -0.0363],\n",
      "        [ 0.0380,  0.0154,  0.0057,  ...,  0.0067,  0.0117, -0.0042]])\n",
      "base_model.model.layers.2.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0102, -0.0101],\n",
      "        [ 0.0158,  0.0164],\n",
      "        [ 0.0144,  0.0154],\n",
      "        ...,\n",
      "        [-0.0041, -0.0041],\n",
      "        [-0.0084, -0.0091],\n",
      "        [ 0.0051,  0.0055]])\n",
      "base_model.model.layers.3.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0005, -0.0399,  0.0193,  ..., -0.0162, -0.0281,  0.0020],\n",
      "        [-0.0076, -0.0038,  0.0051,  ..., -0.0039, -0.0206,  0.0172]])\n",
      "base_model.model.layers.3.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0056, -0.0062],\n",
      "        [-0.0051, -0.0042],\n",
      "        [ 0.0060,  0.0052],\n",
      "        ...,\n",
      "        [ 0.0049,  0.0048],\n",
      "        [-0.0022, -0.0046],\n",
      "        [-0.0029, -0.0033]])\n",
      "base_model.model.layers.4.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0310,  0.0106,  0.0102,  ..., -0.0128, -0.0168,  0.0065],\n",
      "        [ 0.0108,  0.0007, -0.0304,  ..., -0.0073,  0.0233, -0.0203]])\n",
      "base_model.model.layers.4.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0004, -0.0104],\n",
      "        [ 0.0059, -0.0018],\n",
      "        [ 0.0069, -0.0063],\n",
      "        ...,\n",
      "        [-0.0029, -0.0075],\n",
      "        [-0.0134,  0.0125],\n",
      "        [ 0.0048,  0.0065]])\n",
      "base_model.model.layers.5.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0062,  0.0002, -0.0254,  ...,  0.0333, -0.0129, -0.0044],\n",
      "        [-0.0065, -0.0073, -0.0199,  ..., -0.0002, -0.0134, -0.0138]])\n",
      "base_model.model.layers.5.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0009,  0.0015],\n",
      "        [ 0.0004, -0.0007],\n",
      "        [ 0.0003, -0.0033],\n",
      "        ...,\n",
      "        [ 0.0061,  0.0037],\n",
      "        [ 0.0088,  0.0085],\n",
      "        [-0.0076, -0.0071]])\n",
      "base_model.model.layers.6.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0048,  0.0287,  0.0163,  ..., -0.0102,  0.0064,  0.0279],\n",
      "        [-0.0113, -0.0107,  0.0014,  ..., -0.0063, -0.0083,  0.0180]])\n",
      "base_model.model.layers.6.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 6.1076e-03, -3.4664e-05],\n",
      "        [-1.2838e-02, -6.2463e-03],\n",
      "        [ 1.0459e-02,  1.1677e-02],\n",
      "        ...,\n",
      "        [ 5.5465e-03,  5.9227e-03],\n",
      "        [-1.2671e-02, -1.2801e-02],\n",
      "        [ 1.1740e-03,  1.8042e-03]])\n",
      "base_model.model.layers.7.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-1.0584e-03, -1.9929e-02, -1.0444e-02,  ...,  2.1562e-02,\n",
      "          2.0063e-02,  3.0783e-02],\n",
      "        [ 7.8999e-03,  2.3062e-02,  3.0226e-02,  ..., -2.2790e-02,\n",
      "         -1.4248e-02, -5.8171e-05]])\n",
      "base_model.model.layers.7.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0048, -0.0041],\n",
      "        [-0.0035,  0.0015],\n",
      "        [-0.0017,  0.0040],\n",
      "        ...,\n",
      "        [ 0.0015,  0.0022],\n",
      "        [ 0.0087, -0.0111],\n",
      "        [-0.0085,  0.0081]])\n",
      "base_model.model.layers.8.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0136,  0.0024,  0.0231,  ..., -0.0185, -0.0182, -0.0348],\n",
      "        [-0.0213, -0.0269, -0.0300,  ...,  0.0201,  0.0285,  0.0329]])\n",
      "base_model.model.layers.8.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0021, -0.0014],\n",
      "        [-0.0022,  0.0032],\n",
      "        [-0.0064,  0.0058],\n",
      "        ...,\n",
      "        [ 0.0059, -0.0078],\n",
      "        [-0.0021,  0.0021],\n",
      "        [ 0.0026, -0.0025]])\n",
      "base_model.model.layers.9.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0162,  0.0079,  0.0222,  ..., -0.0313, -0.0138, -0.0296],\n",
      "        [ 0.0111, -0.0009,  0.0068,  ..., -0.0078, -0.0229, -0.0255]])\n",
      "base_model.model.layers.9.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0011, -0.0006],\n",
      "        [ 0.0043,  0.0077],\n",
      "        [ 0.0015,  0.0034],\n",
      "        ...,\n",
      "        [ 0.0055,  0.0063],\n",
      "        [ 0.0034,  0.0036],\n",
      "        [-0.0119, -0.0130]])\n",
      "base_model.model.layers.10.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0114,  0.0019,  0.0137,  ...,  0.0271,  0.0088, -0.0183],\n",
      "        [-0.0332, -0.0086, -0.0339,  ...,  0.0101, -0.0075, -0.0038]])\n",
      "base_model.model.layers.10.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0002, -0.0007],\n",
      "        [-0.0037,  0.0053],\n",
      "        [ 0.0005, -0.0022],\n",
      "        ...,\n",
      "        [-0.0040,  0.0027],\n",
      "        [-0.0084,  0.0096],\n",
      "        [-0.0065,  0.0063]])\n",
      "base_model.model.layers.11.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0069, -0.0297, -0.0091,  ..., -0.0087,  0.0033,  0.0223],\n",
      "        [-0.0102,  0.0362,  0.0046,  ...,  0.0136, -0.0080, -0.0209]])\n",
      "base_model.model.layers.11.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0078, -0.0083],\n",
      "        [ 0.0089, -0.0091],\n",
      "        [ 0.0120, -0.0129],\n",
      "        ...,\n",
      "        [ 0.0065, -0.0159],\n",
      "        [-0.0017, -0.0015],\n",
      "        [-0.0094,  0.0146]])\n",
      "base_model.model.layers.12.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0164, -0.0013, -0.0177,  ...,  0.0033, -0.0277,  0.0304],\n",
      "        [-0.0034,  0.0043, -0.0191,  ..., -0.0263, -0.0361,  0.0285]])\n",
      "base_model.model.layers.12.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0090, -0.0077],\n",
      "        [-0.0036, -0.0041],\n",
      "        [ 0.0013,  0.0048],\n",
      "        ...,\n",
      "        [-0.0120, -0.0132],\n",
      "        [ 0.0104,  0.0097],\n",
      "        [-0.0043, -0.0024]])\n",
      "base_model.model.layers.13.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0097, -0.0039, -0.0243,  ..., -0.0291, -0.0010,  0.0020],\n",
      "        [ 0.0037,  0.0136,  0.0193,  ...,  0.0126,  0.0314, -0.0129]])\n",
      "base_model.model.layers.13.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0076,  0.0054],\n",
      "        [-0.0126,  0.0125],\n",
      "        [-0.0044,  0.0053],\n",
      "        ...,\n",
      "        [-0.0168,  0.0171],\n",
      "        [ 0.0080, -0.0067],\n",
      "        [-0.0161,  0.0157]])\n",
      "base_model.model.layers.14.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0059, -0.0035,  0.0236,  ...,  0.0022,  0.0067,  0.0093],\n",
      "        [-0.0072, -0.0024,  0.0179,  ...,  0.0242,  0.0323, -0.0029]])\n",
      "base_model.model.layers.14.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0042,  0.0046],\n",
      "        [ 0.0036,  0.0026],\n",
      "        [ 0.0046,  0.0052],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0130],\n",
      "        [ 0.0017, -0.0016],\n",
      "        [-0.0061, -0.0060]])\n",
      "base_model.model.layers.15.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0050,  0.0072, -0.0387,  ..., -0.0012, -0.0046, -0.0213],\n",
      "        [-0.0018,  0.0011, -0.0026,  ..., -0.0167, -0.0282,  0.0073]])\n",
      "base_model.model.layers.15.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 5.6150e-05, -1.2257e-03],\n",
      "        [ 6.2287e-04,  3.1606e-04],\n",
      "        [-4.9014e-04, -2.7994e-04],\n",
      "        ...,\n",
      "        [ 1.4730e-02,  2.2121e-03],\n",
      "        [-7.7577e-03, -4.7923e-03],\n",
      "        [-3.2478e-03,  1.3804e-03]])\n",
      "base_model.model.layers.16.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0023,  0.0255,  0.0331,  ...,  0.0320,  0.0193, -0.0094],\n",
      "        [ 0.0308, -0.0146, -0.0102,  ...,  0.0003, -0.0135,  0.0304]])\n",
      "base_model.model.layers.16.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0067, -0.0069],\n",
      "        [ 0.0081, -0.0089],\n",
      "        [-0.0129,  0.0121],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0062],\n",
      "        [ 0.0121, -0.0113],\n",
      "        [ 0.0076, -0.0068]])\n",
      "base_model.model.layers.17.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0097, -0.0104,  0.0084,  ...,  0.0125,  0.0101, -0.0243],\n",
      "        [-0.0229, -0.0099,  0.0285,  ...,  0.0008,  0.0168,  0.0123]])\n",
      "base_model.model.layers.17.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 5.7279e-03,  5.7354e-03],\n",
      "        [ 2.8610e-03,  2.7644e-03],\n",
      "        [-1.3654e-03, -4.8468e-04],\n",
      "        ...,\n",
      "        [-3.8957e-05, -4.0397e-04],\n",
      "        [ 1.2176e-02,  1.3191e-02],\n",
      "        [-4.1291e-03, -3.0717e-03]])\n",
      "base_model.model.layers.18.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0058, -0.0158, -0.0124,  ..., -0.0373, -0.0094, -0.0035],\n",
      "        [-0.0138,  0.0040,  0.0292,  ...,  0.0358,  0.0201,  0.0121]])\n",
      "base_model.model.layers.18.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0026,  0.0032],\n",
      "        [ 0.0029, -0.0018],\n",
      "        [ 0.0013, -0.0007],\n",
      "        ...,\n",
      "        [ 0.0029, -0.0015],\n",
      "        [ 0.0134, -0.0146],\n",
      "        [-0.0135,  0.0090]])\n",
      "base_model.model.layers.19.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0190, -0.0189, -0.0040,  ...,  0.0047, -0.0321,  0.0174],\n",
      "        [-0.0190, -0.0057,  0.0043,  ..., -0.0121,  0.0045, -0.0038]])\n",
      "base_model.model.layers.19.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.9518e-03, -8.9604e-04],\n",
      "        [-3.1821e-04, -1.3305e-03],\n",
      "        [ 1.0700e-04,  4.4242e-05],\n",
      "        ...,\n",
      "        [-3.0390e-03,  8.1827e-03],\n",
      "        [-2.5057e-04,  7.5845e-05],\n",
      "        [-4.2283e-03,  5.2138e-03]])\n",
      "base_model.model.layers.20.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0068,  0.0095, -0.0112,  ..., -0.0148,  0.0315, -0.0266],\n",
      "        [-0.0029, -0.0028,  0.0284,  ...,  0.0103, -0.0361, -0.0055]])\n",
      "base_model.model.layers.20.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0035, -0.0023],\n",
      "        [-0.0044,  0.0024],\n",
      "        [-0.0031,  0.0033],\n",
      "        ...,\n",
      "        [-0.0180,  0.0161],\n",
      "        [ 0.0006,  0.0017],\n",
      "        [-0.0012, -0.0002]])\n",
      "base_model.model.layers.21.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0036, -0.0114,  0.0281,  ...,  0.0064, -0.0402,  0.0291],\n",
      "        [ 0.0321, -0.0356,  0.0340,  ..., -0.0292, -0.0041,  0.0230]])\n",
      "base_model.model.layers.21.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0124,  0.0140],\n",
      "        [-0.0049, -0.0081],\n",
      "        [-0.0116, -0.0134],\n",
      "        ...,\n",
      "        [ 0.0104,  0.0102],\n",
      "        [-0.0040, -0.0044],\n",
      "        [ 0.0078,  0.0070]])\n",
      "base_model.model.layers.22.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0147, -0.0152,  0.0090,  ..., -0.0044, -0.0375, -0.0069],\n",
      "        [ 0.0111, -0.0009,  0.0060,  ...,  0.0021, -0.0021, -0.0254]])\n",
      "base_model.model.layers.22.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-5.0596e-03,  5.2203e-03],\n",
      "        [-2.9551e-03,  2.7678e-03],\n",
      "        [ 1.6012e-03, -1.7714e-03],\n",
      "        ...,\n",
      "        [ 7.3957e-04, -7.4552e-04],\n",
      "        [ 7.7997e-03, -8.3549e-03],\n",
      "        [ 7.2557e-04, -8.3839e-05]])\n",
      "base_model.model.layers.23.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0115,  0.0176,  0.0261,  ...,  0.0155,  0.0352,  0.0140],\n",
      "        [-0.0233, -0.0039, -0.0243,  ..., -0.0322, -0.0089,  0.0003]])\n",
      "base_model.model.layers.23.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0137, -0.0116],\n",
      "        [ 0.0122, -0.0145],\n",
      "        [ 0.0148, -0.0137],\n",
      "        ...,\n",
      "        [ 0.0123, -0.0057],\n",
      "        [-0.0134,  0.0122],\n",
      "        [-0.0059,  0.0079]])\n",
      "base_model.model.layers.24.mixer.Wqkv.lora_A.default.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0304,  0.0020, -0.0155,  ..., -0.0321, -0.0002, -0.0022],\n",
      "        [-0.0038, -0.0205,  0.0218,  ...,  0.0156,  0.0233,  0.0365]])\n",
      "base_model.model.layers.24.mixer.Wqkv.lora_B.default.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0014,  0.0012],\n",
      "        [ 0.0066, -0.0065],\n",
      "        [-0.0091,  0.0093],\n",
      "        ...,\n",
      "        [-0.0211,  0.0214],\n",
      "        [ 0.0126, -0.0127],\n",
      "        [-0.0038,  0.0042]])\n"
     ]
    }
   ],
   "source": [
    "for n, p in peft_model.named_parameters():\n",
    "    if 'lora' in n:\n",
    "        print(n)\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/code_alpaca_v2.json', encoding='utf-8') as fin:\n",
    "    data = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can create this but it won't help me map to original index ... \n",
    "new_tasks = [{'instruction': t['instruction'], 'output': t['output']}\n",
    "             for t in data if t['phi_base_output'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = phi15.make_prompts_for_tests_gen(new_tasks[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Problem:\n",
      "        Fix the following function to make it comply with PEP8 standards.\n",
      "\n",
      "        Solution:\n",
      "        def f(x):\n",
      "    k = x + 4\n",
      "    return k\n",
      "\n",
      "        Test cases:\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "def generate(model, tokenizer, data, responses=[]):\n",
    "    for i in range(len(responses), len(data), batch_size):\n",
    "        print(i, end=' ')\n",
    "        #prompts = phi15.make_prompts_for_tests_gen(data[i:i+batch_size])\n",
    "        responses.extend(phi15.gen_n_prompts(model, tokenizer, data))\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated GPU Memory: 7.94 GB\n",
      "Maximum Allocated GPU Memory: 11.88 GB\n",
      "Available GPU Memory: 7.85 GB\n"
     ]
    }
   ],
   "source": [
    "from laughing import utils\n",
    "\n",
    "utils.free_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "responses = generate(peft_model, tokenizer, prompts, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Problem:          Fix the following function to make it comply with PEP8 standards.          Solution:          def f(x):      k = x + 4      return k          Test cases:          def f(x):\n",
      "    return x + 4\n",
      "\n",
      "def g(x):\n",
      "    return x + 4\n",
      "\n",
      "Problem:\n",
      "\n",
      "def g(x):\n",
      "    return x + 4\n",
      "\n",
      "    def g(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no_return(x):\n",
      "      return x + 4\n",
      "\n",
      "    def test_g_with_return_no_return_no\n",
      "\n",
      "======================\n",
      "         Problem:          Create a function to take in a given array, rotate it by one, so that the last element of the array is now the first element.          Solution:          def rotate_list(arr):       length = len(arr)       temp = arr[length - 1]       for i in range(length-1, 0, -1):          arr[i] = arr[i-1]       arr[0] = temp              return arr\n",
      " \n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "print(rotate_list(my_list))    #Output: [5, 1, 2, 3, 4]          Test cases:          print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(rotate_list([1, 2, 3, 4, 5]))    #Output: [5, 1, 2, 3, 4]\n",
      "print(\n",
      "\n",
      "======================\n",
      "         Problem:          Create an algorithm to find out the longest common sub-sequence between two string inputs.          Solution:          def LCSubStr(Str1, Str2):      n = len(Str1)      m = len(Str2)      LCSuff = [0] * (n + 1)      LCSuff = [[0 for k in range(m + 1)] for l in range(n + 1)]          result = 0           for i in range(n):          for j in range(m):                 if (Str1[i] == Str2[j]):                  LCSuff[i + 1][j + 1] =LCSuff[i][j] + 1                  if (LCSuff[i + 1][j + 1] > result):                      result = LCSuff[i + 1][j + 1]      return result          Test cases:          def test_LCSubStr():      assert LCSubStr(\"ABCD\", \"ACD\") == 2, \"Test case 1 failed\"      def test_LCSubStr_with_empty_string():      assert LCSubStr(\"\", \"\") == 0, \"Test case 2 failed\"      def test_LCSubStr_with_single_characters():      assert LCSubStr(\"A\", \"A\") == 1, \"Test case 3 failed\"      def test_LCSubStr_with_multiple_characters():      assert LCSubStr(\"ABCD\", \"ACD\") == 2, \"Test case 4 failed\"      def test_LCSubStr_with_mixed_characters():      assert LCSubStr(\"ABCD\", \"ABD\") == 0, \"Test case 5 failed\"      def test_LCSubStr_with_numbers():      assert LCSubStr(\"ABCD\", \"1234\") == 0, \"Test case 6 failed\"      def test_LCSubStr_with_special_characters():      assert LCSubStr(\"ABCD\", \"@#\") == 0, \"Test case 7 failed\"      def test_LCSubStr_with_spaces():      assert LCSubStr(\"ABCD\", \"    \") == 0, \"Test case 8 failed\"      def test_LCSubStr_with_special_characters_and_spaces():      assert LCSubStr(\"ABCD\", \"@#    \") == 0, \"Test case 9 failed\"      def test_LCSubStr_with_special_characters_and_spaces_with_numbers():      assert LCSubStr(\"ABCD\", \"@#    1234\") == 0, \"Test case 10 failed\"      def test_LCSubStr_with_special_characters_and_spaces_with_numbers_with_mixed_characters():      assert LCSubStr(\"ABCD\", \"@#    1234\") == 0, \"Test case 11 failed\"      def test_LCSubStr_with_special_characters_and_spaces_with_numbers_with_mixed_characters_and_empty_string():      assert LCSubStr(\"@#    1234\", \"\") == 0, \"Test case 12 failed\"      def test_LCSubStr_with_special_characters_and_spaces_with_numbers_with_\n",
      "\n",
      "======================\n",
      "         Problem:          Create a function in Python that will take two parameters: a string and an integer, and return the string repeated the amount of times specified by the integer.          Solution:          def repeat(string, num_repetitions):      return string * num_repetitions          Test cases:          print(repeat(\"hello\", 3))    # Output: hellohellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return string * num_repetitions\n",
      "\n",
      "print(repeat(\"hello\", 3))    # Output: hellohellohello\n",
      "\n",
      "def repeat(string, num_repetitions):\n",
      "      return\n",
      "\n",
      "======================\n",
      "         Problem:          Write a Python function that validates a given credit card number.          Solution:          def validate(number):\n",
      "\"\"\" Validate credit card number using Luhn algorithm \"\"\"    num = [int(x) for x in str(number)]    return (sum(num[::-2] + [sum(divmod(d*2,10)) for d in num[-2::-2]]) % 10 == 0          Test cases:          [    1,    2,    3,    4,    5,    6,    7,    8,    9, 10]    Solution:    def validate(number):    return sum(num[::-2] + [sum(divmod(d*2, 10)) % 10 for d in num[-2::-2]] == [sum(num[-2::-2]) % 10]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9, 10]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,    8,    9,    0]    Test cases:    [    1,    2,    3,    4,    5,    6,    7,\n",
      "\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "for x in responses:\n",
    "    print(x)\n",
    "    print('\\n======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.inference_mode()\n",
    "def gen_test_cases(model, tokenizer, prompts, max_new_tokens:int=300):\n",
    "    \"\"\"Generate test cases for a batch of tasks using a model.\"\"\"\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", return_attention_mask=False,\n",
    "                       padding=True, truncation=True).to('cuda')\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens,\n",
    "                             eos_token_id=tokenizer.eos_token_id)\n",
    "    texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "responses = gen_test_cases(peft_model, tokenizer, prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate unit tests for the below problem and its solution in Python.          Write each unit test as a seperate Python function with meaningful name that starts with 'test_'.          Problem:          Fix the following function to make it comply with PEP8 standards.          Solution:          def f(x):      k = x + 4      return k          Test cases:          def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:    def f(x):    return x + 4    Test cases:   \n",
      "\n",
      "=====================\n",
      "\n",
      "Generate unit tests for the below problem and its solution in Python.          Write each unit test as a seperate Python function with meaningful name that starts with 'test_'.          Problem:          Create a function to take in a given array, rotate it by one, so that the last element of the array is now the first element.          Solution:          def rotate_list(arr):       length = len(arr)       temp = arr[length - 1]       for i in range(length-1, 0, -1):          arr[i] = arr[i-1]       arr[0] = temp              return arr\n",
      " \n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "print(rotate_list(my_list))    #Output: [5, 1, 2, 3, 4]          Test cases:          assert rotate_list(my_list)    #Test cases:          assert rotate_list([1, 2, 3, 4, 5])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([1, 2, 3, 4, 5])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([1, 2, 3, 4, 5])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3, 4])    #Test cases:          assert rotate_list([5, 1, 2, 3\n",
      "\n",
      "=====================\n",
      "\n",
      "Generate unit tests for the below problem and its solution in Python.          Write each unit test as a seperate Python function with meaningful name that starts with 'test_'.          Problem:          Create an algorithm to find out the longest common sub-sequence between two string inputs.          Solution:          def LCSubStr(Str1, Str2):      n = len(Str1)      m = len(Str2)      LCSuff = [0] * (n + 1)      LCSuff = [[0 for k in range(m + 1)] for l in range(n + 1)]          result = 0           for i in range(n):          for j in range(m):                 if (Str1[i] == Str2[j]):                  LCSuff[i + 1][j + 1] =LCSuff[i][j] + 1                  if (LCSuff[i + 1][j + 1] > result):                      result = LCSuff[i + 1][j + 1]      return result          Test cases:          def test_LCSubStr():      assert LCSubStr(\"ABCD\", \"ABCD\") == 2      assert LCSubStr(\"ABCD\", \"BCD\") == 1      assert LCSubStr(\"ABCD\", \"CDE\") == 0      assert LCSubStr(\"ABCD\", \"DEF\") == 0      assert LCSubStr(\"ABCD\", \"EFG\") == 0      assert LCSubStr(\"ABCD\", \"HIJ\") == 0      assert LCSubStr(\"ABCD\", \"KLM\") == 0      assert LCSubStr(\"ABCD\", \"NOP\") == 0      assert LCSubStr(\"ABCD\", \"QRST\") == 0      assert LCSubStr(\"ABCD\", \"STU\") == 0      assert LCSubStr(\"ABCD\", \"VWX\") == 0      assert LCSubStr(\"ABCD\", \"XYZ\") == 0      assert LCSubStr(\"ABCD\", \"ABCD\") == 0      assert LCSubStr(\"ABCD\", \"ABCD\") == 0      assert LCSubStr(\"ABCD\", \"ABCD\") == 0      Test cases:          def test_LCSubStr_with_special_characters():      assert LCSubStr(\"ABCD\", \"ABCD\") == 2      assert LCSubStr(\"ABCD\", \"BCD\") == 1      assert LCSubStr(\"ABCD\", \"CDE\") == 0      assert LCSub\n",
      "\n",
      "=====================\n",
      "\n",
      "Generate unit tests for the below problem and its solution in Python.          Write each unit test as a seperate Python function with meaningful name that starts with 'test_'.          Problem:          Create a function in Python that will take two parameters: a string and an integer, and return the string repeated the amount of times specified by the integer.          Solution:          def repeat(string, num_repetitions):      return string * num_repetitions          Test cases:          def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_string(string, num_repetitions):    return string * num_repetitions    Test cases:    def repeat_\n",
      "\n",
      "=====================\n",
      "\n",
      "Generate unit tests for the below problem and its solution in Python.          Write each unit test as a seperate Python function with meaningful name that starts with 'test_'.          Problem:          Write a Python function that validates a given credit card number.          Solution:          def validate(number):\n",
      "\"\"\" Validate credit card number using Luhn algorithm \"\"\"    num = [int(x) for x in str(number)]    return (sum(num[::-2] + [sum(divmod(d*2,10)) for d in num[-2::-2]]) % 10 == 0          Test cases:          def validate(number):    # Test cases    Solution:    def validate(number):    # Test cases    Test cases:    def validate(number):    # Test cases:    def validate(number):    # Test cases:    def validate(number):    def validate(number):    # Test cases:    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):    def validate(number):   \n",
      "\n",
      "=====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in responses:\n",
    "    print(x)\n",
    "    print('\\n=====================\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
